{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('marvin_v2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7f2490a7909a0b1041f3a47ebb71872ac623417d99b53437ed1400d7705c5ac2"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is made to gernerate science maps from MaNGA datacubes using Marvin software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check my current environment\n",
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from marvin.tools.maps import Maps\n",
    "from marvin.tools.image import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "import glob\n",
    "import pandas as pd\n",
    "from marvin import config\n",
    "config.setRelease('DR16')\n",
    "#import plotly.express as px\n",
    "#import plotly.graph_objects as go"
   ]
  },
  {
   "source": [
    "## Masking function using the map data mask value to replace bad value with np.nan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_masking(map_arr, mask_arr, fill_val=np.nan, real_val=0):\n",
    "    \"\"\"\n",
    "    Masking function to replace bad values (>0) of a 2d np.ndarray with a fill value\n",
    "\n",
    "    Code:\n",
    "        map_arr[mask_arr != real_val] = fill_val\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "        map_arr: ndarray\n",
    "            2D ndarray with original values\n",
    "\n",
    "        mask_arr: ndarray\n",
    "            2D ndarray of the mask array and must be the same shape as map_arr\n",
    "\n",
    "        fill_val: int, float, np,nan, np.inf (Default=np.nan)\n",
    "            The value that will be substituted for the bad values in the map array\n",
    "\n",
    "        real_val: int or float (Default=0)\n",
    "            The value that repersents good value in the mask array\n",
    "    \"\"\"\n",
    "\n",
    "    map_arr[mask_arr != real_val] = fill_val\n",
    "\n",
    "    return map_arr"
   ]
  },
  {
   "source": [
    "# Balmer Decrement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balmer_dec(obs_haflux, obs_hbflux):\n",
    "    '''\n",
    "    Calculates Balmer decrement (Ha_flux / Hb_flux)\n",
    "    \n",
    "    Paremeters:\n",
    "        obs_haflux: float, numpy.ndarray, marvin.tools.quantities.map.Map \n",
    "            Observed Halpha flux value or Map\n",
    "        \n",
    "        obs_hbflux: float, numpy.ndarray, marvin.tools.quantities.map.Map\n",
    "            Observed Hbeta flux value or Map\n",
    "    '''\n",
    "    bdec = obs_haflux / obs_hbflux\n",
    "    return bdec\n"
   ]
  },
  {
   "source": [
    "# Calzetti extinction curve 2000 Function "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c00_k(wavelength, Rv=4.05):\n",
    "    '''\n",
    "    Calzetti extinction curve 2000 (Good for starburst like dust)\n",
    "    Paremeters:\n",
    "    \n",
    "        wavelength: float, \n",
    "            units of microns\n",
    "        \n",
    "        Rv: float, \n",
    "            normilaztion of the extinction curve\n",
    "    '''\n",
    "    if np.logical_and(wavelength >= 0.63, wavelength <= 2.2):\n",
    "        #k_lambda = 1.17 * (-1.857 + (1.040/rest_lam)) + 1.78 # Calzetti 2001 obscuration code\n",
    "        k_lambda = 2.659 * (-1.857 + (1.040/wavelength)) + Rv # Calzetti 2000\n",
    "        #print('k_lambda={}'.format(k_lambda))\n",
    "    elif np.logical_and(wavelength >= 0.12, wavelength < 0.63):\n",
    "        #k_lambda = 1.17 * (-2.156 + (1.509/rest_lam) - (0.198/rest_lam**2) + (0.011/rest_lam**3)) + 1.78 # Calzetti 2001 obscuration code\n",
    "        k_lambda = 2.659 * (-2.156 + (1.509/wavelength) - (0.198/wavelength**2) + (0.011/wavelength**3)) + Rv\n",
    "        #print('k_lambda={}'.format(k_lambda))\n",
    "    else:\n",
    "        print('Rest wavelength is not in range or not in Angstroms {}'.format(wavelength))\n",
    "        \n",
    "    return k_lambda\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def c00_kcorr(obs_flux, obs_wavelength, bdec, Rv=4.05):\n",
    "    '''\n",
    "    Extinction correction using the Calzetti extinction curve\n",
    "    \n",
    "    Paremeter:\n",
    "        obs_flux: float, numpy.ndarray, marvin.tools.quantities.map.Map\n",
    "            Obsereved flux value or map [1e-17erg/cm^2/s/spaxel]\n",
    "        \n",
    "        obs_wavelength: float, \n",
    "            wavelength [micron]\n",
    "\n",
    "        bdec: float, numpy.ndarray, marvin.tools.quantities.map.Map\n",
    "            Balmer Decrement (Ha/Hb)\n",
    "            *Must be same type as obs_flux*\n",
    "        \n",
    "        Rv: float, curve normilization\n",
    "    '''\n",
    "    \n",
    "    # Observe flux\n",
    "    #print('Observe Flux = {} 1e-17erg/cm^2/spaxel/s'.format(obs_flux))\n",
    "    \n",
    "    # Observe extinction curve \n",
    "    obs_k = c00_k(obs_wavelength, Rv=Rv)\n",
    "    #print('k({} mircon) = {}'.format(obs_wavelength, obs_k))\n",
    "    \n",
    "    # Ha, Hb extinction curve\n",
    "    k_Ha = c00_k(.6564, Rv)\n",
    "    #print('k({} mircon) = {}'.format(.6564, k_Ha))\n",
    "    k_Hb = c00_k(.4864, Rv)\n",
    "    #print('k({} mircon) = {}'.format(.4864, k_Hb))\n",
    "    \n",
    "    # Optical depth tau\n",
    "    tau = np.log10(bdec / 2.86) # possibly np.log10\n",
    "    #print('Balmer optical depth={}'.format(tau))\n",
    "    \n",
    "    # color excess(gas) - Battisti et al 2017 eqn 2\n",
    "    EBV_gas = (1.086 / (k_Hb - k_Ha)) * tau \n",
    "    EBV_star = EBV_gas * 0.44\n",
    "    #print('E(B-V)gas={}'.format(EBV_gas))\n",
    "    #print('E(B-V)star={}'.format(EBV_star))\n",
    "    \n",
    "    # Intrinsic flux [erg/cm^2/s]\n",
    "    int_flux = obs_flux * 10**(0.4 * obs_k * EBV_star)\n",
    "    #print('intrinsic_flux = {} 1e-17erg/cm^2/s'.format(int_flux))\n",
    "    #print('')\n",
    "    \n",
    "    return int_flux"
   ]
  },
  {
   "source": [
    "# Star formation rate density"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfr_map2(halphadc_map, z):\n",
    "    \"\"\"\n",
    "    Paremters:\n",
    "        halphadc_map\n",
    "    \n",
    "    \"\"\"\n",
    "    #sfr_map = (7.9e-42 * halphadc_map) / 1.53\n",
    "    \n",
    "    # Calculate Luminosity distance\n",
    "    cosmo = FlatLambdaCDM(H0=70 * u.km / u.s / u.Mpc, Tcmb0=2.725 * u.K, Om0=0.3)\n",
    "    lum_d_mpc = cosmo.luminosity_distance(z)\n",
    "    lum_d_cm = lum_d_mpc.to(u.cm).value # convert from Mpc to cm\n",
    "    #print('Lum Distance {} converted to {} cm'.format(lum_d_mpc, lum_d_cm))\n",
    "    \n",
    "    #Convert flux to Luminosity\n",
    "    l_ha = halphadc_map * (4 * np.pi * (lum_d_cm**2)) #1e-17 erg / (s spaxel)\n",
    "    #print('Halpha Flux: ',halphadc_map[27,27])\n",
    "    #print('Halpha Luminosity: ',l_ha[27,27])\n",
    "    \n",
    "    #sfr - Salpeter initial mass function Hao et al. (2011)\n",
    "    sfr_map = (8.79e-42 * l_ha) # [Msolar/yr]\n",
    "    #print('SFR: ',sfr_map[27,27])\n",
    "    \n",
    "    spaxel_size = 0.5  # [arcsec]\n",
    "    c = 299792  # speed of light [km/s]\n",
    "    H0 = 70  # [km s^-1 Mpc^-1]\n",
    "    D = c * z / H0  # approx. distance to galaxy [Mpc]\n",
    "\n",
    "    scale = 1 / 206265 * D * 1e6  # 1 radian = 206265 arcsec [pc / arcsec]\n",
    "    spaxel_area_pc = (scale * spaxel_size)**2 * u.pc**2 # [pc^2]\n",
    "    spaxel_area_kpc = spaxel_area_pc.to(u.kpc**2)\n",
    "\n",
    "    #Calculate the SFRD of each spaxel\n",
    "    sfrd_map = sfr_map / spaxel_area_kpc.value\n",
    "\n",
    "    ##Measeure the diameter of each spaxel with respect to the galaxy distance\n",
    "    #spaxel_diamter_in_kpc = cosmo.kpc_proper_per_arcmin(z).to(u.kpc/u.arcsec) * (0.5 * u.arcsec)\n",
    "    ##print('Diamter of each spaxel (0.5 arcsec) on the galaxy: {}'.format(spaxel_diamter_in_kpc))\n",
    "    #\n",
    "    ##Area of each spaxel\n",
    "    #Area_of_each_spaxels =  4 * np.pi * (spaxel_diamter_in_kpc/2)**2\n",
    "    ##print('Area of each spaxel: {}'.format(Area_of_each_spaxels))\n",
    "    #\n",
    "    ##Calculate the SFRD of each spaxel\n",
    "    #sfrd_map = sfr_map / Area_of_each_spaxels\n",
    "    ##print('SFRD: ',sfrd_map[27,27])\n",
    "    \n",
    "    return sfr_map, l_ha, sfrd_map, spaxel_area_kpc"
   ]
  },
  {
   "source": [
    "# Radius Map and effective radius from Marvin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_ratio_map(plateifu):\n",
    "    '''\n",
    "    platifu: str \n",
    "    \n",
    "    '''\n",
    "    #Galaxy effective radius\n",
    "    r_eff = float(Maps(plateifu=plateifu).header['reff']) #arcsec\n",
    "    #print('Effective Radius', Reff)\n",
    "    \n",
    "    # Galaxy elliptical radius\n",
    "    r_map = Maps(plateifu=plateifu).spx_ellcoo_elliptical_radius.value #arcsec\n",
    "    #print('Elliptical Radius', R)\n",
    "    \n",
    "    #R/Reff\n",
    "    radius_ratio = r_map / r_eff\n",
    "    \n",
    "    return r_map, radius_ratio, r_eff"
   ]
  },
  {
   "source": [
    "# Metallicity Maps functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2o2_Z_map(nii6585_fluxmap, oii3727_fluxmap, oii3729_fluxmap):\n",
    "    # Kewley and Dopita - 2002 - Using Strong Lines to Estimate Abundances in Extra (KD02)\n",
    "    # NII/OII diagnostic [N II] λ6584/[O II] λ3727,3729\n",
    "    # Note: Independent of ionization parameter, Z>=8.6 for a reliable abundance\n",
    "    fratio_map = np.log10(nii6585_fluxmap / (oii3727_fluxmap+oii3729_fluxmap))\n",
    "    Z_map = np.log10(1.54020 + (1.26602 * fratio_map) + (0.167977 * fratio_map**2)) + 8.93 # KD02 (eq 5&7) [Z = log(O/H) +12]\n",
    "    return fratio_map, Z_map\n",
    "\n",
    "def o3n2_metal_map(o3_5008_fluxmap, nii6585_fluxmap, ha_fluxmap, hb_fluxmap):\n",
    "    # Marino et al. 2013 O3N2 diagnostic\n",
    "    # O3N2 diagnostic [OIII]λ5007/Hbeta * Halpha/[NII]λ6583\n",
    "    fratio_map = np.log10((o3_5008_fluxmap/hb_fluxmap) * (ha_fluxmap / nii6585_fluxmap))\n",
    "    Z_map = 8.505 - 0.221 * fratio_map\n",
    "    return fratio_map, Z_map\n",
    "\n",
    "def n2_metal_map(nii6585_fluxmap, ha_fluxmap):\n",
    "    # Marino et al. 2013 N2 diagnostic\n",
    "    # N2 diagnostic log([NII]λ6583/Halpha)\n",
    "    fratio_map = np.log10(nii6585_fluxmap / ha_fluxmap)\n",
    "    Z_map = 8.667 - 0.455 * fratio_map # Log[O/H] + 12\n",
    "    return fratio_map, Z_map\n",
    "\n",
    "#def n2s2_metal_map(nii6585_fluxmap, sii6718_fluxmap, sii6732_fluxmap, ha_fluxmap):\n",
    "#    # Marino et al. 2013 N2 diagnostic\n",
    "#    # N2S2 diagnostic log([NII]λ6583/Halpha)\n",
    "#    n2_ratio_map, n2_Z_map = n2_metal_map(nii6585_fluxmap, ha_fluxmap) # \n",
    "#    fratio_map = np.log10(nii6585_fluxmap / (sii6718_fluxmap + sii6732_fluxmap))\n",
    "#    metal_map = 8.77 + fratio_map + 0.264 * n2_Z_map\n",
    "#    return ratio_map, metal_map"
   ]
  },
  {
   "source": [
    "# Pipe3D Maps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe3D Maps\n",
    "def pipe3d_maps(plateifu, sample='bbrd'):\n",
    "    '''\n",
    "    Parameters:\n",
    "        plateifu: str\n",
    "            MaNGA plateifu\n",
    "    \n",
    "    Return:\n",
    "    age_l, age_Z, age_err, stel_vel, vel_err, v_disp, v_err, ml_ratio, mass_density\n",
    "    '''\n",
    "    #SSP\n",
    "    hdu = fits.open('/Users/mmckay/Desktop/research/FMR_MZR/{}_pipe3d_fits/manga-{}.Pipe3D.cube.fits'.format(sample, plateifu))\n",
    "    age_l = hdu[1].data[5,:,:] # Gyr - Luminosity Weighted age\n",
    "    age_m = hdu[1].data[6,:,:] # Gyr - Mass Weighted age \n",
    "    age_err =  hdu[1].data[7,:,:] # Gyr - Error of the age\n",
    "    metal_l = hdu[1].data[8,:,:] # Luminosity Weighted metallicity of the stellar population (where Z=0.02 is solar metallicity)\n",
    "    metal_m = hdu[1].data[9,:,:] # Mass Weighted metallicity of the stellar population\n",
    "    metal_err =   hdu[1].data[10,:,:] # Error of the metallicity of the stellar population\n",
    "    stel_vel = hdu[1].data[13,:,:] # [km/s] Velocity map of the stellar population\n",
    "    vel_err = hdu[1].data[14,:,:] # Error in the velocity of the stellar population\n",
    "    v_disp = hdu[1].data[15,:,:] # Velocity dispersion of the stellar population (sigma)\n",
    "    v_err = hdu[1].data[16,:,:] # Error in velocity dispersion of the stellar population\n",
    "    ml_ratio = hdu[1].data[17,:,:] # [Log(Msun/Lsun)] Average mass-to-light ratio of the stellar population\n",
    "    mass_rho = hdu[1].data[19,:,:] # [Log(Msun/spaxels^2)] Stellar Mass density per pixel with dust correction\n",
    "    mass_rho = hdu[1].data[19,:,:] # [Log(Msun/spaxels^2)] Stellar Mass density per pixel with dust correction\n",
    "\n",
    "    #INDCICES - not corrected for velocity dispersion\n",
    "    d4000_index = hdu[4].data[5,:,:] # D4000 index map\n",
    "    d4000_err = hdu[4].data[13,:,:] #D4000 index err map\n",
    "    hdelta_index = hdu[4].data[6,:,:] #Hdelta index map\n",
    "    hdelta_err = hdu[4].data[14,:,:] #Hdelta index map\n",
    "\n",
    "    hdu.close()\n",
    "\n",
    "    return age_l, age_m, age_err, metal_l, metal_m, metal_err, stel_vel, vel_err, v_disp, v_err, ml_ratio, mass_rho, d4000_index, d4000_err, hdelta_index, hdelta_err"
   ]
  },
  {
   "source": [
    "# Generating Maps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_maps2fits(plateifu, mode='local', sample='bbrd'):\n",
    "    \n",
    "    # Load Marvin Maps\n",
    "    maps = Maps(plateifu=plateifu, mode=mode)\n",
    "\n",
    "    # flux maps\n",
    "    ha6564flux_map = maps.emline_gflux_ha_6564 # [1e-17 erg / (cm s spaxel)]\n",
    "    hb4862flux_map = maps.emline_gflux_hb_4862\n",
    "    nii6585_map = maps.emline_gflux_nii_6585\n",
    "    oii3727_map = maps.emline_gflux_oii_3727\n",
    "    oii3729_map = maps.emline_gflux_oii_3729\n",
    "    o3_5008_map = maps.emline_gflux_oiii_5008\n",
    "    sii6718_map = maps.emline_gflux_sii_6718\n",
    "    sii6732_map = maps.emline_gflux_sii_6732\n",
    "    snr_map = maps.spx_snr # SNR map\n",
    "\n",
    "    # Remove bad pixels values from Maps and replaces them with a fill_val\n",
    "    ha_map_clean = map_masking(map_arr=ha6564flux_map.value, mask_arr=ha6564flux_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    hb_map_clean = map_masking(map_arr=hb4862flux_map.value, mask_arr=hb4862flux_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    nii6585_map_clean = map_masking(map_arr=nii6585_map.value, mask_arr=nii6585_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    oii3727_map_clean = map_masking(map_arr=oii3727_map.value, mask_arr=oii3727_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    oii3729_map_clean = map_masking(map_arr=oii3729_map.value, mask_arr=oii3729_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    o3_5008_map_clean = map_masking(map_arr=o3_5008_map.value, mask_arr=o3_5008_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    sii6718_map_clean = map_masking(map_arr=sii6718_map.value, mask_arr=sii6718_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "    sii6732_map_clean = map_masking(map_arr=sii6732_map.value, mask_arr=sii6732_map.mask, fill_val=np.nan, real_val=0) # remove bad spaxels\n",
    "\n",
    "\n",
    "    # Balmer Decrrement\n",
    "    bdec_map = balmer_dec(obs_haflux=ha_map_clean, obs_hbflux=hb_map_clean)\n",
    "    bdec_map[bdec_map == np.inf] = 0.0 # Replace inf values with zero incase hbeta map had zero values\n",
    "\n",
    "    # Run kcorrection function on emission lines\n",
    "    ha_mapdc = c00_kcorr(ha_map_clean, .6564, bdec_map, Rv=4.05)\n",
    "    hb_mapdc = c00_kcorr(hb_map_clean, .4864, bdec_map, Rv=4.05)\n",
    "    nii6585_mapdc = c00_kcorr(nii6585_map_clean, .6585, bdec_map, Rv=4.05)\n",
    "    oii3727_mapdc = c00_kcorr(oii3727_map_clean, .3727, bdec_map, Rv=4.05)\n",
    "    oii3729_mapdc = c00_kcorr(oii3729_map_clean, .3729, bdec_map, Rv=4.05)\n",
    "    o3_5008_mapdc = c00_kcorr(o3_5008_map_clean, .5008, bdec_map, Rv=4.05)\n",
    "    sii6718_mapdc = c00_kcorr(sii6718_map_clean, .6718, bdec_map, Rv=4.05)\n",
    "    sii6732_mapdc = c00_kcorr(sii6732_map_clean, .6732, bdec_map, Rv=4.05)\n",
    "\n",
    "    # Get redshift\n",
    "    z = maps.nsa['z']\n",
    "\n",
    "    # Run Star formation code\n",
    "    #sfr_map, l_ha, sfrd_map, spaxel_diamter_in_kpc, Area_of_each_spaxels = sfr_map(halphadc_map=ha_mapdc, z=z)\n",
    "    sfr_map, l_ha, sfrd_map, spaxel_area_kpc = sfr_map2(halphadc_map=ha_mapdc/1e17, z=z)\n",
    "\n",
    "    # Radius Map\n",
    "    r_map, radius_ratio, r_eff = radius_ratio_map(plateifu=plateifu)\n",
    "\n",
    "    # Log(O/H)+12 - N2O2\n",
    "    n2o2_ratiomap, n2o2_metalmap = n2o2_Z_map(nii6585_mapdc, oii3727_mapdc, oii3729_mapdc)\n",
    "\n",
    "    # Log(O/H)+12 - O3N2\n",
    "    o3n2_ratiomap, o3n2_metalmap = o3n2_metal_map(o3_5008_fluxmap=o3_5008_mapdc, nii6585_fluxmap=nii6585_mapdc, ha_fluxmap=ha_mapdc,hb_fluxmap=hb_mapdc)\n",
    "\n",
    "    # Log(O/H)+12 - NII/Ha\n",
    "    n2_ratiomap, n2_metalmap = n2_metal_map(nii6585_fluxmap=nii6585_mapdc, ha_fluxmap=ha_mapdc)\n",
    "\n",
    "    # Pipe3D Maps\n",
    "    age_l, age_m, age_err, metal_l, metal_m, metal_err, stel_vel, vel_err, v_disp, v_err, ml_ratio, mass_rho, d4000_index, d4000_err, hdelta_index, hdelta_err = pipe3d_maps(plateifu, sample=sample)\n",
    "\n",
    "    # Bluck et al. 2020 delta SFR = SFRD - Bluck least square minimization \n",
    "    sfms_fit_map = 0.90 * mass_rho - 9.57 # Bluck least square minimization fit\n",
    "    delta_sfr = sfrd_map - sfms_fit_map \n",
    "\n",
    "\n",
    "    # Write Maps to FITS file\n",
    "    #Writes a new fits for the data\n",
    "    new_hdul = fits.HDUList()\n",
    "    new_hdul.append(fits.ImageHDU(ha_map_clean, ver=1, name='Halpha')) # Halpha [1e-17 erg / (cm2 s spaxel)]\n",
    "    new_hdul.append(fits.ImageHDU(ha_mapdc, name='Halpha Kcorr',ver=2)) # Halpha k-corrected [1e-17 erg / (cm2 s spaxel)]\n",
    "    new_hdul.append(fits.ImageHDU(snr_map.value, ver=3, name='SNR')) # SNR\n",
    "    new_hdul.append(fits.ImageHDU(bdec_map, ver=4, name='Ha/Hb')) # Balmer decerment\n",
    "    new_hdul.append(fits.ImageHDU(l_ha, ver=5, name='Ha Lum')) # erg / (s spaxel)\n",
    "    new_hdul.append(fits.ImageHDU(sfr_map, ver=6, name='SFR')) # Msolar/yr\n",
    "    new_hdul.append(fits.ImageHDU(sfrd_map, ver=7, name='SFR Density')) #Msolar/yr/kpc^2\n",
    "    new_hdul.append(fits.ImageHDU(r_map, ver=8, name='Ellip R')) # arcsec\n",
    "    new_hdul.append(fits.ImageHDU(radius_ratio, ver=9, name='R/Reff'))\n",
    "    new_hdul.append(fits.ImageHDU(n2o2_metalmap, ver=10, name='Log(O/H)+12_[N2O2]'))\n",
    "    new_hdul.append(fits.ImageHDU(o3n2_metalmap, ver=11, name='Log(O/H)+12_[O3N2]'))\n",
    "    new_hdul.append(fits.ImageHDU(n2_metalmap, ver=12, name='Log(O/H)+12_[N2]'))\n",
    "    new_hdul.append(fits.ImageHDU(age_l, ver=13, name='Gyr_lw'))\n",
    "    new_hdul.append(fits.ImageHDU(age_m, ver=14, name='Gyr_mw'))\n",
    "    new_hdul.append(fits.ImageHDU(age_err, ver=15, name='Gyr_err'))\n",
    "    new_hdul.append(fits.ImageHDU(metal_l, ver=16, name='SP_ZsubL'))\n",
    "    new_hdul.append(fits.ImageHDU(metal_m, ver=17, name='SP_ZsubM'))\n",
    "    new_hdul.append(fits.ImageHDU(metal_err, ver=18, name='SP_Zerr'))\n",
    "    new_hdul.append(fits.ImageHDU(stel_vel, ver=19, name='Vel_km/s'))\n",
    "    new_hdul.append(fits.ImageHDU(vel_err, ver=20, name='Vel_err]'))\n",
    "    new_hdul.append(fits.ImageHDU(v_disp, ver=21, name='Vdisp_km/s'))\n",
    "    new_hdul.append(fits.ImageHDU(v_err, ver=22, name='Vdisp_err'))\n",
    "    new_hdul.append(fits.ImageHDU(ml_ratio, ver=23, name='M/L'))\n",
    "    new_hdul.append(fits.ImageHDU(mass_rho, ver=24, name='Msun/spx2'))\n",
    "    new_hdul.append(fits.ImageHDU(mass_rho/0.25, ver=25, name='Msun/arcs2'))\n",
    "    new_hdul.append(fits.ImageHDU(mass_rho/spaxel_area_kpc.value, ver=26, name='Msun/kpc2'))\n",
    "    new_hdul.append(fits.ImageHDU(d4000_index, ver=27, name='D4000'))\n",
    "    new_hdul.append(fits.ImageHDU(d4000_err, ver=28, name='D4000_err'))\n",
    "    new_hdul.append(fits.ImageHDU(hdelta_index, ver=29, name='Hdelta'))\n",
    "    new_hdul.append(fits.ImageHDU(hdelta_err, ver=30, name='Hdelta_err'))\n",
    "\n",
    "\n",
    "    # Update header\n",
    "    prihdr = new_hdul[0].header\n",
    "    prihdr['SPX_AREA']='{} Kpc^2'.format(str(spaxel_area_kpc.value)[:5])\n",
    "    prihdr['REFF']='{} ARCSECS'.format(str(r_eff)[:5])\n",
    "    prihdr['z']='{} redshift'.format(str(z)[:5])\n",
    "    prihdr['plateifu']=plateifu\n",
    "\n",
    "    # Write data to FITS file\n",
    "    new_hdul.writeto('/Users/mmckay/Desktop/research/FMR_MZR/{}_result_fits/{}_results.fits'.format(sample, plateifu), overwrite=True)"
   ]
  },
  {
   "source": [
    "# Generate FITS files with IFU maps"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbrd sample\n",
    "for plateifu in ['8550-12703', '8312-12704', '10001-3702', '8254-1902', '8595-3703']:\n",
    "    #print(plateifu)\n",
    "    fits_maps = write_maps2fits(plateifu, mode='local', sample='bbrd')\n",
    "    # Check '8465-9102' - not working - is it downloaded locally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Lg12 sample\n",
    "lg12_plateifu_df = pd.read_csv('/Users/mmckay/Desktop/research/FMR_MZR/lg12_manga_table.csv')\n",
    "for plateifu in lg12_plateifu_df['plateifu']:\n",
    "    #print(plateifu)\n",
    "    try: # Some files were not found due to missing pipe3d fits files \n",
    "        fits_maps = write_maps2fits(plateifu, mode='local', sample='lg12')\n",
    "    except:\n",
    "        print(plateifu)"
   ]
  },
  {
   "source": [
    "# Make IFU maps in 1D columns and stores in pandas dataframe for each galaxy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input 2d data as a 1d Series in a dataframe\n",
    "# 1. Interable Function to read in FITS file extensions - done\n",
    "# 2. Flatten 2D maps array to 1D column array\n",
    "# 3. Add Columns to pandas DataFrame\n",
    "# 4. Append each galaxy dataframe to combo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read FITS file extension \n",
    "def read_fits_ext(fits_file, ext=1):\n",
    "    hdu = fits.open(fits_file)\n",
    "    sci_maps = hdu[ext].data\n",
    "    hdu.close()\n",
    "    return sci_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store 2D Maps as 1D columns in a pandas dataframe\n",
    "# List of BBRD FITS files\n",
    "fits_filelist = glob.glob('/Users/mmckay/Desktop/research/FMR_MZR/bbrd_result_fits/*.fits')\n",
    "fits_filelist\n",
    "\n",
    "# \n",
    "extnum_list = np.arange(1,31,1) # The range of FITS extension\n",
    "for fit in fits_filelist:\n",
    "    hdu = fits.open(fit)\n",
    "    ifu_df = pd.DataFrame()\n",
    "    for extnum in extnum_list:\n",
    "        # Read in 2d data from fits file extension \n",
    "        map2d_data = read_fits_ext(fit, ext=hdu[extnum-1].name)\n",
    "        #Flatten 2d map\n",
    "        map1d_data = map2d_data.flatten(order='C')\n",
    "        #print(extnum, hdu[extnum-1].ver, hdu[extnum-1].name, map1d_data.shape)\n",
    "        # Pair extname column with the 1D Map data\n",
    "        ifu_df[hdu[extnum-1].name] = map1d_data\n",
    "        \n",
    "    print(ifu_df.shape)\n",
    "    ifu_df.to_csv(path_or_buf='/Users/mmckay/Desktop/research/FMR_MZR/bbrd_result_fits/{}_map.csv'.format(hdu[0].header['plateifu']), sep=',')\n",
    "    hdu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LG12\n",
    "# Store 2D Maps as 1D columns in a pandas dataframe\n",
    "# List of BBRD FITS files\n",
    "fits_filelist = glob.glob('/Users/mmckay/Desktop/research/FMR_MZR/lg12_result_fits/*.fits')\n",
    "fits_filelist\n",
    "\n",
    "# \n",
    "extnum_list = np.arange(1,31,1) # The range of FITS extension\n",
    "for fit in fits_filelist:\n",
    "    hdu = fits.open(fit)\n",
    "    ifu_df = pd.DataFrame()\n",
    "    for extnum in extnum_list:\n",
    "        # Read in 2d data from fits file extension \n",
    "        map2d_data = read_fits_ext(fit, ext=hdu[extnum-1].name)\n",
    "        #Flatten 2d map\n",
    "        map1d_data = map2d_data.flatten(order='C')\n",
    "        #print(extnum, hdu[extnum-1].ver, hdu[extnum-1].name, map1d_data.shape)\n",
    "        # Pair extname column with the 1D Map data\n",
    "        ifu_df[hdu[extnum-1].name] = map1d_data\n",
    "        \n",
    "    #print(ifu_df.shape)\n",
    "    ifu_df.to_csv(path_or_buf='/Users/mmckay/Desktop/research/FMR_MZR/lg12_result_fits/{}_map.csv'.format(hdu[0].header['plateifu']), sep=',')\n",
    "    hdu.close()"
   ]
  },
  {
   "source": [
    "# Combine all dataframes in the sample into a super dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into a super dataframe\n",
    "bbrd_csv_list = glob.glob('/Users/mmckay/Desktop/research/FMR_MZR/bbrd_result_fits/*_map.csv')\n",
    "csv_list = []\n",
    "for bbrd in bbrd_csv_list:\n",
    "    bbrd_df = pd.read_csv(bbrd)\n",
    "    print(bbrd, bbrd_df.shape)\n",
    "    csv_list.append(bbrd_df)\n",
    "\n",
    "#len(csv_list)\n",
    "bbrd_supercsv = pd.concat(csv_list)\n",
    "bbrd_supercsv.to_csv(path_or_buf='/Users/mmckay/Desktop/research/FMR_MZR/bbrd_result_fits/bbrd_mastertable.csv', sep=',')\n",
    "\n",
    "print(bbrd_supercsv.shape)\n",
    "bbrd_supercsv.head(10)\n",
    "# Replace inf value with nans\n",
    "#bbrd_supercsv_clean = bbrd_supercsv.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#pd.set_option('use_inf_as_na', True) # compute inf values as nans\n",
    "\n",
    "# LG12 sample\n",
    "# Combine all dataframes into a super dataframe\n",
    "lg12_csv_list = glob.glob('/Users/mmckay/Desktop/research/FMR_MZR/lg12_result_fits/*_map.csv')\n",
    "csv_list = []\n",
    "for csv in lg12_csv_list:\n",
    "    csv_df = pd.read_csv(csv)\n",
    "    print(csv, bbrd_df.shape)\n",
    "    csv_list.append(csv_df)\n",
    "\n",
    "#len(csv_list)\n",
    "lg12_supercsv = pd.concat(csv_list)\n",
    "lg12_supercsv.to_csv(path_or_buf='/Users/mmckay/Desktop/research/FMR_MZR/lg12_result_fits/lg12_mastertable.csv', sep=',')\n",
    "\n",
    "print(lg12_supercsv.shape)\n",
    "lg12_supercsv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/mmckay/Desktop/research/FMR_MZR/lg12_result_fits/lg12_mastertable.csv', sep=',')"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the data from FITS file\n",
    "plateifu = '8550-12703'\n",
    "sample = 'bbrd'\n",
    "hdu_8550_12703 = fits.open('/Users/mmckay/Desktop/research/FMR_MZR/{}_result_fits/{}_results.fits'.format(sample, plateifu))\n",
    "hdu_8550_12703.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_8550_12703[0].header['*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu_8550_12703[3].ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maps = Maps(plateifu='8465-9102', mode='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_maps2fits('8465-9102', mode='remote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}